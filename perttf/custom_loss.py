# Modified from scGPT
import torch
import torch.nn.functional as F
from torch import nn
from typing import Optional


from scgpt.loss import (
    masked_mse_loss,
    masked_relative_error,
    criterion_neg_log_bernoulli,
)

def semi_masked_mse_loss(
    input: torch.Tensor, target: torch.Tensor, mask: torch.Tensor, alpha = 0.7
) -> torch.Tensor:
    """
    Compute the masked MSE loss between input and target.
    """
    mask = mask.float()
    loss_mask = F.mse_loss(input * mask, target * mask, reduction="sum") / mask.sum()
    loss_other = F.mse_loss(input * (1 - mask), target * (1 - mask), reduction="sum") / (1- mask).sum()
    loss = loss_other*(1-alpha) + loss_mask*alpha
    return loss 


def criterion_semi_neg_log_bernoulli(
    input: torch.Tensor, target: torch.Tensor, mask: torch.Tensor, alpha = 0.7
) -> torch.Tensor:
    """
    Compute the negative log-likelihood of Bernoulli distribution
    """
    mask = mask.float()
    bernoulli = torch.distributions.Bernoulli(probs=input)
    log_probs = bernoulli.log_prob((target > 0).float())
    masked_log_probs_mask = log_probs * mask / mask.sum()
    masked_log_probs_other = log_probs * (1- mask) / (1 - mask).sum()
    masked_log_probs = masked_log_probs_other*(1-alpha) + masked_log_probs_mask*alpha
    return -masked_log_probs.sum()


def semi_masked_relative_error(
    input: torch.Tensor, target: torch.Tensor, mask: torch.LongTensor, alpha = 0.7
) -> torch.Tensor:
    """
    Compute the masked relative error between input and target.
    """
    assert mask.any()
    #loss_mask = torch.abs(input[mask] - target[mask]) / (target[mask] + 1e-6)
    loss = torch.abs(input- target) / (target + 1e-6)
    loss[mask] = loss[mask]*alpha
    loss[~mask] = loss[~mask]*(1-alpha)
    #loss_other = torch.abs(input[~mask] - target[~mask]) / (target[~mask] + 1e-6)
    #loss = loss_other*(1-alpha) + loss_mask*alpha
    return loss.mean()





def l1_loss_flexible(
    v_head: torch.Tensor,
    target: torch.Tensor,
    mask: torch.Tensor,
    p_head: Optional[torch.Tensor] = None,
    alpha: float = 0.7,
) -> torch.Tensor:
    """
    Computes a flexible L1 loss with weighted masking.

    If p_head is provided, it computes the unified loss where the final prediction
    is the product of the probability and value heads (y_pred = p_head * v_head).

    If p_head is None, it computes a standard L1 loss directly on the value
    head (y_pred = v_head).

    Args:
        v_head (torch.Tensor): The output of the continuous value head.
        target (torch.Tensor): The ground truth sparse vector.
        mask (torch.Tensor): The binary mask tensor. 1 for primary loss positions.
        p_head (Optional[torch.Tensor]): The optional output of the probability
                                           head (after sigmoid, in [0, 1]).
                                           Defaults to None.
        alpha (float): The weight for the loss on the masked positions.

    Returns:
        torch.Tensor: The final computed loss value.
    """
    # Step 1: Create the prediction based on whether p_head is provided
    if p_head is not None:
        # Unified model: prediction is the gated value
        y_pred = p_head * v_head
    else:
        # Standard model: prediction is just the value
        y_pred = v_head

    # --- The rest of the logic remains the same ---

    # Ensure mask is float for calculations
    mask = mask.float()

    # Step 2: Calculate the per-element absolute error
    abs_error = torch.abs(y_pred - target)

    # Step 3: Calculate the mean loss for the masked and unmasked parts separately
    # Add a small epsilon (1e-8) to the denominator to prevent division by zero
    sum_mask = mask.sum()
    loss_mask = (abs_error * mask).sum() / (sum_mask + 1e-8)

    sum_other = (1 - mask).sum()
    loss_other = (abs_error * (1 - mask)).sum() / (sum_other + 1e-8)

    # Step 4: Combine the losses using the alpha weight
    loss = loss_mask * alpha + loss_other * (1 - alpha)
    
    # Handle cases where one of the masks is empty
    if sum_mask == 0 and sum_other > 0:
        loss = loss_other
    elif sum_other == 0 and sum_mask > 0:
        loss = loss_mask
        
    return loss


def zinb_loss(y_true, mean, dispersion, pi_nonzero, eps=1e-8):
    """
    Calculates the Zero-Inflated Negative Binomial (ZINB) loss.

    Args:
        y_true (torch.Tensor): The true expression counts (ground truth).
        mean (torch.Tensor): The predicted mean (mu) of the NB component.
                             Must be positive.
        dispersion (torch.Tensor): The predicted dispersion (theta) of the NB
                                   component. Must be positive.
        pi_nonzero (torch.Tensor): The predicted probability of the count being
                                   generated by the NB component (non-zero probability).
                                   Must be in the range [0, 1].
        eps (float): A small epsilon value for numerical stability.

    Returns:
        torch.Tensor: The mean loss for the batch.
    """
    # Ensure inputs have the same shape
    if y_true.shape != mean.shape or y_true.shape != dispersion.shape or y_true.shape != pi_nonzero.shape:
        raise ValueError("All input tensors must have the same shape.")

    # --- Likelihood for non-zero counts (y > 0) ---
    # This is the log-likelihood of the NB distribution, scaled by pi_nonzero
    log_nb_part = (
        torch.lgamma(y_true + dispersion)
        - torch.lgamma(dispersion)
        - torch.lgamma(y_true + 1)
        + dispersion * torch.log(dispersion + eps)
        + y_true * torch.log(mean + eps)
        - (dispersion + y_true) * torch.log(dispersion + mean + eps)
    )
    log_pi_part = torch.log(pi_nonzero + eps)
    
    # Combine to get the negative log-likelihood for the NB case
    nb_case = -(log_pi_part + log_nb_part)

    # --- Likelihood for zero counts (y = 0) ---
    # P(y=0) = (1-pi) [structural zero] + pi * P(NB=0 | mean, disp) [NB zero]
    prob_nb_zero = (dispersion / (dispersion + mean + eps)) ** dispersion
    prob_zero = (1 - pi_nonzero) + pi_nonzero * prob_nb_zero
    
    # Negative log-likelihood for the zero case
    zero_case = -torch.log(prob_zero + eps)

    # Combine cases based on y_true
    loss = torch.where(y_true > 0, nb_case, zero_case)

    return torch.mean(loss)
    

def aggregate_losses(config, input_dict, output_dict, metric_prefix = 'train'):
    criterion = masked_mse_loss
    criterion_dab = nn.CrossEntropyLoss()
    criterion_cls = nn.CrossEntropyLoss()
    criterion_pert = nn.CrossEntropyLoss()
    criterion_adv = nn.CrossEntropyLoss()  # consider using label smoothing
    criterion_ps = nn.MSELoss() # this is the loss for predicting PS scores
    #criterion_ps = nn.CrossEntropyLoss()

    input_values = input_dict['input_values']
    target_values = input_dict['target_values']
    target_values_next = input_dict['target_values_next']
    celltype_labels = input_dict['celltype_labels']
    celltype_labels_next = input_dict['celltype_labels_next']
    perturbation_labels = input_dict['perturbation_labels']
    perturbation_labels_next = input_dict['perturbation_labels_next']
    ps_score = input_dict['ps_score']
    ps_score_next = input_dict['ps_score_next']
    batch_labels = input_dict['batch_labels']

    if hasattr(config, "pred_lochness_next"):
        has_lochness_next_pred = True
        ps_next_training_weight = config.pred_lochness_next
    else:
        has_lochness_next_pred = False
        ps_next_training_weight = config.ps_weight * config.next_weight

    masked_positions = input_values.eq(config.mask_value)  # the postions to predict
    loss_dict = {}
    loss_dict['loss_mse'] = criterion(
        output_dict["mlm_output"], target_values, masked_positions
    )
    loss = config.this_weight * loss_dict['loss_mse']
    metrics_to_log = {metric_prefix+"mse": loss['loss_mse'].item()}
    # next value?
    loss_dict['loss_mse_next'] = criterion(
        output_dict["mlm_output"],
        target_values_next, masked_positions
    )
    # disable now, target_values_next, target_values, 
    #loss = loss + config.next_weight * loss_mse_next
    metrics_to_log.update({metric_prefix+"mse_next": loss_dict['loss_mse_next'].item()})

    if config.explicit_zero_prob:
        loss_dict['loss_zero_log_prob'] = criterion_neg_log_bernoulli(
            output_dict["mlm_zero_probs"], target_values, masked_positions
        )
        loss = loss + config.this_weight *loss_dict['loss_zero_log_prob']
        metrics_to_log.update({metric_prefix+"nzlp": loss_dict['loss_zero_log_prob'].item()})
        # added
        loss['loss_zero_log_prob_next'] = criterion_neg_log_bernoulli(
            output_dict["mlm_zero_probs"], target_values_next, masked_positions
        )
        #loss = loss + config.next_weight *loss_zero_log_prob_next
        metrics_to_log.update({metric_prefix+"nzlp_next": loss_dict['loss_zero_log_prob_next'].item()})
    if config.GEPC:
        loss['loss_gepc'] = criterion(
            output_dict["mvc_output"], target_values, masked_positions
        )
        loss = loss + config.this_weight *loss_dict['loss_gepc']
        metrics_to_log.update({metric_prefix+"mvc": loss_dict['loss_gepc'].item()})
        # added
        loss_dict['loss_gepc_next'] = criterion(
            output_dict["mvc_output_next"], target_values_next, masked_positions
        )
        loss = loss + config.next_weight * loss_dict['loss_gepc_next']
        metrics_to_log.update({metric_prefix+"mvc_next": loss_dict['loss_gepc_next'].item()})
    if config.GEPC and config.explicit_zero_prob:
        loss_dict['loss_gepc_zero_log_prob'] = criterion_neg_log_bernoulli(
            output_dict["mvc_zero_probs"], target_values, masked_positions
        )
        loss = loss + config.this_weight * loss_dict['loss_gepc_zero_log_prob'] 
        metrics_to_log.update(
            {metric_prefix+"/mvc_nzlp": loss_dict['loss_gepc_zero_log_prob'].item()}
        )
        # added
        loss_dict['loss_gepc_zero_log_prob_next'] = criterion_neg_log_bernoulli(
            output_dict["mvc_zero_probs_next"], target_values_next, masked_positions
        )
        loss = loss + config.next_weight * loss_dict['loss_gepc_zero_log_prob_next'] 
        metrics_to_log.update(
            {metric_prefix+"/mvc_nzlp_next": loss['loss_gepc_zero_log_prob_next'].item()}
        )
    if config.cell_type_classifier:
        loss_dict['loss_cls'] = criterion_cls(output_dict["cls_output"], celltype_labels)
        loss = loss + config.cell_type_classifier_weight * loss_dict['loss_cls']
        metrics_to_log.update({metric_prefix+"/cls": loss_dict['loss_cls'].item()})
        # add for next cls prediction
        loss_dict['loss_cls_next'] = criterion_cls(output_dict["cls_output_next"], celltype_labels_next)
        loss = loss + config.cell_type_classifier_weight * config.next_weight *  loss_dict['loss_cls_next']
        metrics_to_log.update({metric_prefix+"/cls_next": loss_dict['loss_cls_next'].item()})

        error_rate = 1 - (
            (output_dict["cls_output"].argmax(1) == celltype_labels)
            .sum()
            .item()
        ) / celltype_labels.size(0)

    if config.perturbation_classifier_weight > 0:
        loss_dict['loss_pert'] = criterion_pert(output_dict["pert_output"], perturbation_labels)
        loss = loss + config.perturbation_classifier_weight * loss_dict['loss_pert']
        metrics_to_log.update({metric_prefix+"/pert": loss_dict['loss_pert'].item()})
        # add for next pert prediction
        loss_dict['loss_pert_next'] = criterion_pert(output_dict["pert_output_next"], perturbation_labels_next)
        loss = loss + config.perturbation_classifier_weight * config.next_weight * loss_dict['loss_pert_next']
        metrics_to_log.update({metric_prefix+"/pert_next": loss_dict['loss_pert_next'].item()})

    if config.ps_weight >0:
        loss_dict["loss_ps"] = criterion_ps(output_dict["ps_output"], ps_score)
        #import pdb; pdb.set_trace()
        #print(f"loss_ps: {loss_ps}")
        loss = loss + config.ps_weight * loss_dict["loss_ps"]
        metrics_to_log.update({metric_prefix+"/ps": loss_dict["loss_ps"].item()})
        loss_ps_next = criterion_ps(output_dict["ps_output_next"], ps_score_next)
        loss = loss + ps_next_training_weight * loss_dict["loss_ps_next"]
        metrics_to_log.update({metric_prefix+"/ps_next": loss_dict["loss_ps_next"].item()})

    if config.ecs_thres > 0:
        loss_dict["loss_ecs"] = config.ecs_weight  * output_dict["loss_ecs"]
        loss = loss + loss_dict["loss_ecs"]
        metrics_to_log.update({metric_prefix+"/ecs": loss_dict["loss_ecs"].item()})
    if config.dab_weight > 0:
        loss_dict["loss_dab"] = criterion_dab(output_dict["dab_output"], batch_labels)
        loss = loss + config.dab_weight * loss_dict["loss_dab"]
        metrics_to_log.update({metric_prefix+"/dab": loss_dict["loss_dab"].item()})

    return loss, metrics_to_log